{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import threading\n",
    "import multiprocessing\n",
    "from multiprocessing import Process\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.读取行为数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b930691bb8b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain_behavior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'timeStamp'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'clickHistory'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'impressionLog'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrain_behavior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'any'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_behavior\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clickHistory'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_behavior\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clickHistory'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mimpressionLog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_behavior\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'impressionLog'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdrop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimpressionLog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/news/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4198\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4200\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-b930691bb8b6>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain_behavior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'timeStamp'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'clickHistory'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'impressionLog'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrain_behavior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'any'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_behavior\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clickHistory'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_behavior\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clickHistory'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mimpressionLog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_behavior\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'impressionLog'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdrop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimpressionLog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('start')\n",
    "start = time.time()\n",
    "# train_behavior = pd.read_csv('./data/train/behaviors.tsv',sep ='\\t',header=None)\n",
    "train_behavior = pd.read_csv('./data/test/testBehavior_social1.csv')\n",
    "###处理 behaviors.tsv 行为数据\n",
    "train_behavior.columns = ['index','id','timeStamp','clickHistory','impressionLog']\n",
    "train_behavior.dropna(axis=0, how='any', inplace=True)\n",
    "train_behavior['clickHistory'] = train_behavior['clickHistory'].apply(lambda x : eval(x))\n",
    "impressionLog = train_behavior['impressionLog'].str.split(' ', expand=True).stack().reset_index(level = 1,drop = True)\n",
    "key, label = impressionLog.str.split('-', 1).str\n",
    "data_new = pd.DataFrame()\n",
    "data_new= train_behavior[['clickHistory']].join(pd.DataFrame(key,columns=['current_news']))\n",
    "data_new['label'] = label\n",
    "data_new['id'] = train_behavior['id']\n",
    "data_new.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "print(data_new.shape[0])\n",
    "print('time is : ',time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clickHistory</th>\n",
       "      <th>current_news</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[N6188, N12021, N59213, N59927, N19508, N21622...</td>\n",
       "      <td>N34090</td>\n",
       "      <td>0</td>\n",
       "      <td>U38457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[N6188, N12021, N59213, N59927, N19508, N21622...</td>\n",
       "      <td>N55355</td>\n",
       "      <td>1</td>\n",
       "      <td>U38457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[N6188, N12021, N59213, N59927, N19508, N21622...</td>\n",
       "      <td>N12700</td>\n",
       "      <td>0</td>\n",
       "      <td>U38457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[N6188, N12021, N59213, N59927, N19508, N21622...</td>\n",
       "      <td>N46738</td>\n",
       "      <td>0</td>\n",
       "      <td>U38457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[N6188, N12021, N59213, N59927, N19508, N21622...</td>\n",
       "      <td>N14368</td>\n",
       "      <td>0</td>\n",
       "      <td>U38457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73151</th>\n",
       "      <td>[N52945, N25654, N38679, N20581, N19145, N5019...</td>\n",
       "      <td>N38188</td>\n",
       "      <td>0</td>\n",
       "      <td>U27142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73151</th>\n",
       "      <td>[N52945, N25654, N38679, N20581, N19145, N5019...</td>\n",
       "      <td>N64402</td>\n",
       "      <td>0</td>\n",
       "      <td>U27142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73151</th>\n",
       "      <td>[N52945, N25654, N38679, N20581, N19145, N5019...</td>\n",
       "      <td>N55355</td>\n",
       "      <td>1</td>\n",
       "      <td>U27142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73151</th>\n",
       "      <td>[N52945, N25654, N38679, N20581, N19145, N5019...</td>\n",
       "      <td>N50337</td>\n",
       "      <td>0</td>\n",
       "      <td>U27142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73151</th>\n",
       "      <td>[N52945, N25654, N38679, N20581, N19145, N5019...</td>\n",
       "      <td>N44819</td>\n",
       "      <td>0</td>\n",
       "      <td>U27142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2658091 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            clickHistory current_news label  \\\n",
       "0      [N6188, N12021, N59213, N59927, N19508, N21622...       N34090     0   \n",
       "0      [N6188, N12021, N59213, N59927, N19508, N21622...       N55355     1   \n",
       "0      [N6188, N12021, N59213, N59927, N19508, N21622...       N12700     0   \n",
       "0      [N6188, N12021, N59213, N59927, N19508, N21622...       N46738     0   \n",
       "0      [N6188, N12021, N59213, N59927, N19508, N21622...       N14368     0   \n",
       "...                                                  ...          ...   ...   \n",
       "73151  [N52945, N25654, N38679, N20581, N19145, N5019...       N38188     0   \n",
       "73151  [N52945, N25654, N38679, N20581, N19145, N5019...       N64402     0   \n",
       "73151  [N52945, N25654, N38679, N20581, N19145, N5019...       N55355     1   \n",
       "73151  [N52945, N25654, N38679, N20581, N19145, N5019...       N50337     0   \n",
       "73151  [N52945, N25654, N38679, N20581, N19145, N5019...       N44819     0   \n",
       "\n",
       "           id  \n",
       "0      U38457  \n",
       "0      U38457  \n",
       "0      U38457  \n",
       "0      U38457  \n",
       "0      U38457  \n",
       "...       ...  \n",
       "73151  U27142  \n",
       "73151  U27142  \n",
       "73151  U27142  \n",
       "73151  U27142  \n",
       "73151  U27142  \n",
       "\n",
       "[2658091 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.读取新闻数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "title_len = 20\n",
    "train_title = pd.read_csv('./data/train/news.tsv',sep='\\t',header=None, encoding='utf-8')\n",
    "test_title = pd.read_csv('./data/test/news.tsv',sep='\\t',header=None, encoding='utf-8')\n",
    "title = pd.concat([train_title,test_title],0)\n",
    "title.columns = ['id','category','sub_category','title','abstract','url','title_entity','abstract_entity']\n",
    "title = title[['id','title']]\n",
    "arr = []\n",
    "for index ,row in title.iterrows():\n",
    "    text = row['title'].split(' ')\n",
    "    text = text[:title_len]\n",
    "    arr.append(text)\n",
    "title['title'] = arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.读取邻居数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighbor = pd.read_csv('./data/nearst_4.csv')\n",
    "# neighbor['nearst'] = neighbor['nearst'].apply(lambda x : eval(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_behavior = pd.read_csv('./data/train/behaviors.tsv',sep ='\\t',header=None)\n",
    "# train_behavior.columns = ['index','id','timeStamp','clickHistory','impressionLog']\n",
    "# test_behavior = pd.read_csv('./data/test/behaviors.tsv',sep ='\\t',header=None)\n",
    "# test_behavior.columns = ['index','id','timeStamp','clickHistory','impressionLog']\n",
    "\n",
    "# behavior = pd.concat([train_behavior,test_behavior],0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91935it [00:13, 6703.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# neighbor_dict = dict()\n",
    "# for index,row in tqdm(neighbor.iterrows()):\n",
    "#     neighbor_dict[row['user']] = row['nearst']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.多线程生成具体行为数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.生成用户对应的历史记录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b.生成对应的用户点击新闻、候选新闻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n"
     ]
    }
   ],
   "source": [
    "print('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "1 2 0 ::4  300 : : \n",
      "\n",
      "6057 8  \n",
      "10 \n",
      "139:::12   14:1618 0 15110\n",
      "  17  1922:: 20021:0\n",
      "  : :\n",
      "   :0 26 : 23 \n",
      "0\n",
      ":240:025 \n",
      " 3129 ::035:36:  30  27  00     : \n",
      "\n",
      "32 33\n",
      ":3438\n",
      "0    ::\n",
      ":37: :  \n",
      "0 :0:\n",
      "4428  394000:045    \n",
      "\n",
      " 42:46 0\n",
      ":::: :  0    0   041:0\n",
      ":\n",
      ":: \n",
      "\n",
      "    :000 00  0:0:0 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "43\n",
      "\n",
      " \n",
      "0\n",
      "  0\n",
      "  0:00\n",
      "\n",
      "\n",
      "00 0 \n",
      " 0\n",
      "\n",
      "\n",
      "0:0\n",
      "\n",
      "\n",
      " 0\n",
      "\n",
      "curernt over:  1\n",
      "47 : 0\n",
      "curernt over:  3\n",
      "curernt over:  47\n",
      "curernt over:  2\n",
      "curernt over:  4\n",
      "curernt over:  5\n",
      "curernt over:  6\n",
      "curernt over:  7\n",
      "curernt over:  8\n",
      "curernt over:  9\n",
      "curernt over:  10\n",
      "curernt over:  12\n",
      "curernt over:  11\n",
      "curernt over:  23\n",
      "curernt over:  31\n",
      "curernt over:  15\n",
      "curernt over:  36\n",
      "curernt over:  14\n",
      "curernt over:  30\n",
      "curernt over:  29\n",
      "curernt over:  16\n",
      "curernt over:  33\n",
      "curernt over:  27\n",
      "curernt over:  40\n",
      "curernt over:  17\n",
      "curernt over:  35\n",
      "curernt over:  38\n",
      "curernt over:  34\n",
      "curernt over:  18\n",
      "curernt over:  32\n",
      "curernt over:  24\n",
      "curernt over:  13curernt over: \n",
      " 21\n",
      "curernt over:  28\n",
      "curernt over:  26\n",
      "curernt over:  19\n",
      "curernt over:  20\n",
      "curernt over:  37\n",
      "curernt over:  22\n",
      "curernt over:  41\n",
      "curernt over:  44\n",
      "curernt over:  42\n",
      "curernt over:  46\n",
      "curernt over:  45\n",
      "curernt over:  25\n",
      "curernt over:  39\n",
      "curernt over:  43\n",
      "all over!\n",
      "time is : 319.2201738357544  s\n"
     ]
    }
   ],
   "source": [
    "#### \n",
    "\n",
    "punctuation = '!,;:?\"\\''\n",
    "def removeFormat(text):\n",
    "    result = re.sub(r'[{}]+'.format(punctuation),'',text).strip().lower()\n",
    "    return result\n",
    "def sample_data(data,name):\n",
    "    x_id = []\n",
    "    x_news = []\n",
    "    x_title = []\n",
    "    x_title_id = []\n",
    "    x_label = []\n",
    "    maxCount = 15\n",
    "    step = 0\n",
    "    for index,row in (data.iterrows()):\n",
    "        \n",
    "        if(step >= 0 and step % 1000 == 0):\n",
    "            print(name,':',step)\n",
    "        text = []\n",
    "        \n",
    "        if(type( row['clickHistory']) == float): continue\n",
    "        \n",
    "        history = row['clickHistory']\n",
    "        idxs = list(range(len(history)))\n",
    "        np.random.shuffle(idxs)\n",
    "        his_len = len(history)\n",
    "        count = 0\n",
    "        for x in idxs:\n",
    "            if(count == maxCount):break\n",
    "            tit = title[title['id']==history[x]]['title'].values[0]\n",
    "            \n",
    "            if type(tit) == float:continue\n",
    "            text.extend(tit)\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "       \n",
    "        tit = title[title['id'] == row['current_news']]['title'].values[0]\n",
    "        if type(tit) == float:continue\n",
    "      \n",
    "        x_news.append(text)\n",
    "        x_title.append(tit)\n",
    "        x_label.append(int(row['label']))\n",
    "        x_id.append(row['id'])\n",
    "        step += 1\n",
    "        \n",
    "       \n",
    "    all_data = pd.DataFrame()\n",
    "    \n",
    "    all_data['id'] = x_id\n",
    "    all_data['history'] = x_news\n",
    "    all_data['current'] = x_title\n",
    "    all_data['label'] = x_label\n",
    "\n",
    "    all_data['history'] = all_data['history'].apply(lambda x : [removeFormat(y) for y in x])\n",
    "    all_data['current'] = all_data['current'].apply(lambda x : [removeFormat(y) for y in x])\n",
    "    all_data.to_csv('./data/test/order_10/test_{0}.csv'.format(name),index=False)\n",
    "    print('curernt over: ',name)\n",
    "print('start')\n",
    "start = time.time()\n",
    "pool_thread = []\n",
    "groups = 46\n",
    "pool = multiprocessing.Pool(processes=groups)\n",
    "data_temp = data_new.iloc[:20000]\n",
    "\n",
    "for index in range(groups+1):\n",
    "    count_data = data_temp.shape[0] // groups\n",
    "    pool.apply_async(sample_data,(data_temp.iloc[index * count_data:(index+1)*count_data,:],index+1))\n",
    "\n",
    "pool.close()\n",
    "pool.join() \n",
    "\n",
    "print('all over!')\n",
    "print('time is :',time.time() - start,' s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.整合所有多线程数据 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.DataFrame()\n",
    "for index in range(1,48):\n",
    "    print(index)\n",
    "    now = pd.read_csv('./data/test/order_10/test_{0}.csv'.format(index))\n",
    "    data = pd.concat([data,now],axis=0)\n",
    "data.to_csv('./data/test/order_10/all_10_social1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>history</th>\n",
       "      <th>current</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U38457</td>\n",
       "      <td>['1000-hp', 'hennessey', 'maximus', 'gladiator...</td>\n",
       "      <td>['after', 'saugus', 'high', 'school', 'shootin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U38457</td>\n",
       "      <td>['buckeyes', 'chase', 'young', 'borrowed', 'mo...</td>\n",
       "      <td>['then', 'and', 'now', 'what', 'all', 'your', ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U38457</td>\n",
       "      <td>['the', '1000-horsepower', 'club', 'toyota', '...</td>\n",
       "      <td>['former', 'officer', 'held', 'up', 'hotel', '...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U38457</td>\n",
       "      <td>['see', 'vin', 'diesels', '21st', 'birthday', ...</td>\n",
       "      <td>['5', 'arrested', 'in', 'connection', 'with', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U38457</td>\n",
       "      <td>['former', 'nba', 'first-round', 'pick', 'jim'...</td>\n",
       "      <td>['13', 'popular', 'foods', 'people', 'hated', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>U21920</td>\n",
       "      <td>['buckeyes', 'chase', 'young', 'borrowed', 'mo...</td>\n",
       "      <td>['bill', 'russell', 'finally', 'accepts', 'bas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>U21920</td>\n",
       "      <td>['lebron', 'posts', 'latest', 'triple-double',...</td>\n",
       "      <td>['halle', 'berry', 'shares', 'photo', 'of', '6...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>U21920</td>\n",
       "      <td>['newark', 'liberty', 'airports', 'terminal', ...</td>\n",
       "      <td>['miami', 'community', 'police', 'benevolent',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>U21920</td>\n",
       "      <td>['la', 'rivalry', 'takes', 'on', 'new', 'meani...</td>\n",
       "      <td>['pair', 'of', 'new', '1987', 'buick', 'grand'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>U21920</td>\n",
       "      <td>['shaquille', 'oneal', 'charles', 'barkley', '...</td>\n",
       "      <td>['taylor', 'swift', 'rep', 'hits', 'back', 'at...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                            history  \\\n",
       "0   U38457  ['1000-hp', 'hennessey', 'maximus', 'gladiator...   \n",
       "1   U38457  ['buckeyes', 'chase', 'young', 'borrowed', 'mo...   \n",
       "2   U38457  ['the', '1000-horsepower', 'club', 'toyota', '...   \n",
       "3   U38457  ['see', 'vin', 'diesels', '21st', 'birthday', ...   \n",
       "4   U38457  ['former', 'nba', 'first-round', 'pick', 'jim'...   \n",
       "..     ...                                                ...   \n",
       "31  U21920  ['buckeyes', 'chase', 'young', 'borrowed', 'mo...   \n",
       "32  U21920  ['lebron', 'posts', 'latest', 'triple-double',...   \n",
       "33  U21920  ['newark', 'liberty', 'airports', 'terminal', ...   \n",
       "34  U21920  ['la', 'rivalry', 'takes', 'on', 'new', 'meani...   \n",
       "35  U21920  ['shaquille', 'oneal', 'charles', 'barkley', '...   \n",
       "\n",
       "                                              current  label  \n",
       "0   ['after', 'saugus', 'high', 'school', 'shootin...      0  \n",
       "1   ['then', 'and', 'now', 'what', 'all', 'your', ...      1  \n",
       "2   ['former', 'officer', 'held', 'up', 'hotel', '...      0  \n",
       "3   ['5', 'arrested', 'in', 'connection', 'with', ...      0  \n",
       "4   ['13', 'popular', 'foods', 'people', 'hated', ...      0  \n",
       "..                                                ...    ...  \n",
       "31  ['bill', 'russell', 'finally', 'accepts', 'bas...      0  \n",
       "32  ['halle', 'berry', 'shares', 'photo', 'of', '6...      0  \n",
       "33  ['miami', 'community', 'police', 'benevolent',...      0  \n",
       "34  ['pair', 'of', 'new', '1987', 'buick', 'grand'...      0  \n",
       "35  ['taylor', 'swift', 'rep', 'hits', 'back', 'at...      0  \n",
       "\n",
       "[20000 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_news' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-48ab77b8395b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muser_news\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'user_news' is not defined"
     ]
    }
   ],
   "source": [
    "user_news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.训练数据采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2000\n",
      "4000\n",
      "4000\n",
      "6000\n",
      "6000\n",
      "8000\n",
      "8000\n",
      "10000\n",
      "10000\n",
      "12000\n",
      "12000\n",
      "14000\n",
      "14000\n",
      "16000\n",
      "16000\n",
      "18000\n",
      "18000\n",
      "20000\n",
      "20000\n",
      "22000\n",
      "22000\n",
      "24000\n",
      "24000\n",
      "26000\n",
      "26000\n",
      "28000\n",
      "28000\n",
      "30000\n",
      "30000\n",
      "30000\n",
      "32000\n",
      "32000\n",
      "34000\n",
      "34000\n",
      "36000\n",
      "36000\n",
      "38000\n",
      "38000\n",
      "40000\n",
      "40000\n",
      "42000\n",
      "42000\n",
      "42000\n",
      "44000\n",
      "44000\n",
      "46000\n",
      "46000\n",
      "48000\n",
      "48000\n",
      "50000\n",
      "50000\n",
      "52000\n",
      "52000\n",
      "54000\n",
      "54000\n",
      "56000\n",
      "56000\n",
      "58000\n",
      "58000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangzhen/anaconda3/envs/news/lib/python3.6/site-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/huangzhen/anaconda3/envs/news/lib/python3.6/site-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "k = 1 ##邻居数量\n",
    "def remove_sep(data):\n",
    "    temp = []\n",
    "    for x in data:\n",
    "        if x != '[sep]':\n",
    "            if(x == '[pad]'):\n",
    "                x = '[PAD]'\n",
    "            temp.append(x)\n",
    "    return temp\n",
    "\n",
    "def sample_neg(data,number):\n",
    "    k = 1\n",
    "    shape = data.shape[0]\n",
    "    index = 0\n",
    "    index_arr = []\n",
    "    index_neighbor = []\n",
    "    while index < shape:\n",
    "        flag = True\n",
    "        for his in range(k):\n",
    "            if data.iloc[index+his]['label'] != 0:\n",
    "                flag = False\n",
    "                break\n",
    "        if(flag):\n",
    "            for pos in range(k):\n",
    "#                 index_neighbor.append(neighbor[neighbor['user'] == data.iloc[pos+index]['id']]['nearst'].values)\n",
    "                index_arr.append(pos + index)\n",
    "            index += k\n",
    "            if(index + k >= shape):break\n",
    "            while(data.iloc[index]['label'] != 1):\n",
    "                index += 1\n",
    "                if(index + k >= shape):break\n",
    "            if(index + k >= shape):break\n",
    "            index_arr.append(index)\n",
    "#             index_neighbor.append(neighbor[neighbor['user'] == data.iloc[index]['id']]['nearst'].values)\n",
    "        else:\n",
    "            index += 1\n",
    "        if(len(index_arr) >= number):break\n",
    "        if(len(index_arr) % 2000 == 0):print(len(index_arr))\n",
    "        if(index + k >= shape):break \n",
    "    return index_arr,index_neighbor\n",
    "\n",
    "train_data = pd.read_csv('./data/train/order_10/all_10_social1.csv')\n",
    "\n",
    "\n",
    "index_arr,index_neighbor = sample_neg(train_data,number=60000)\n",
    "# for index in tqdm(range(len(index_neighbor))):\n",
    "#     index_neighbor[index] = index_neighbor[index][0]\n",
    "# co_neigh = []\n",
    "# for index in tqdm(range(len(index_neighbor))):\n",
    "#     temp = index_neighbor[index]\n",
    "#     co_neigh.append(temp)\n",
    "data = train_data.iloc[index_arr]\n",
    "\n",
    "data['history'] = data['history'].apply(lambda y :' '.join(remove_sep(eval(y))))\n",
    "data['current'] = data['current'].apply(lambda y :' '.join(remove_sep(eval(y))))\n",
    "# # # data['neighbor'] = co_neigh\n",
    "\n",
    "np.save('./data/bert/15_10_con/social1/train_order.npy',data.values.tolist()[:50000])\n",
    "np.save('./data/bert/15_10_con/social1/dev_order.npy',data.values.tolist()[50000:])\n",
    "train_data = data\n",
    "\n",
    "data = pd.read_csv('./data/test/order_10/all_10_social1.csv').iloc[:10000]\n",
    "# co_neigh = []\n",
    "# for index in tqdm(range(len(data))):\n",
    "#     temp = neighbor[neighbor['user']==data.iloc[index]['id']]['nearst'][:k].values[0]\n",
    "#     co_neigh.append(temp)\n",
    "data['history'] = data['history'].apply(lambda y :' '.join(remove_sep(eval(y))))\n",
    "data['current'] = data['current'].apply(lambda y :' '.join(remove_sep(eval(y))))\n",
    "# data['neighbor'] = co_neigh\n",
    "np.save('./data/bert/15_10_con/social1/test_order.npy',data.values.tolist())\n",
    "test_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_emb = pd.read_csv('./data/users_emb.csv')\n",
    "emb_dict = dict()\n",
    "for index ,row in tqdm(users_emb.iterrows()):\n",
    "    emb_dict[row['user']] = row['emb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "title_len = 10\n",
    "train_title = pd.read_csv('./data/train/news.tsv',sep='\\t',header=None, encoding='utf-8')\n",
    "train_title.columns = ['id','category','sub_category','title','abstract','url','title_entity','abstract_entity']\n",
    "test_title = train_title[['id','title']]\n",
    "arr = []\n",
    "for index ,row in train_title.iterrows():\n",
    "    text = row['title'].split(' ')\n",
    "    if(len(text) < title_len):\n",
    "        text.extend(['[PAD]'] * (title_len - len(text)))\n",
    "    else:\n",
    "        text = text[:title_len]\n",
    "    text.append('[SEP]')\n",
    "    arr.append(text)\n",
    "train_title['title'] = arr\n",
    "\n",
    "test_title = pd.read_csv('./data/test/news.tsv',sep='\\t',header=None, encoding='utf-8')\n",
    "test_title.columns = ['id','category','sub_category','title','abstract','url','title_entity','abstract_entity']\n",
    "test_title = test_title[['id','title']]\n",
    "arr = []\n",
    "for index ,row in test_title.iterrows():\n",
    "    text = row['title'].split(' ')\n",
    "    if(len(text) < title_len):\n",
    "        text.extend(['[PAD]'] * (title_len - len(text)))\n",
    "    else:\n",
    "        text = text[:title_len]\n",
    "    text.append('[SEP]')\n",
    "    arr.append(text)\n",
    "test_title['title'] = arr\n",
    "title = pd.concat([train_title,test_title],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_behavior = pd.read_csv('./data/train/behaviors.tsv',sep ='\\t',header=None)\n",
    "# train_behavior.columns = ['index','id','timeStamp','clickHistory','impressionLog']\n",
    "# test_behavior   = pd.read_csv('./data/test/behaviors.tsv',sep ='\\t',header=None)\n",
    "# test_behavior.columns = ['index','id','timeStamp','clickHistory','impressionLog']\n",
    "# all_behavior = pd.concat([train_behavior,test_behavior],0)\n",
    "# behavior_dict =  dict()\n",
    "# for index,row in tqdm(all_behavior.iterrows()):\n",
    "    \n",
    "#     behavior_dict[row['id']] = row['clickHistory']\n",
    "# train_id = train_data[['id']]\n",
    "maxCount = 5\n",
    "train_his = []\n",
    "for index,row in tqdm(train_id.iterrows()):\n",
    "    user = neighbor_dict[row['id']][2]##邻居用户\n",
    "    history = behavior_dict[user]\n",
    "    print(history)\n",
    "    idxs = list(range(len(history)))\n",
    "    np.random.shuffle(idxs)\n",
    "    his_len = len(history)\n",
    "    count = 0\n",
    "    text = []\n",
    "    for x in idxs:\n",
    "        if(count == maxCount):break\n",
    "        print(history[x])\n",
    "        tit = title[title['id']==history[x]]['title'].values[0]\n",
    "        if type(tit) == float:continue\n",
    "        text.extend(tit)\n",
    "        count += 1\n",
    "    train_his.append(text)    \n",
    "test_id = test_data[['id']]\n",
    "test_his = []\n",
    "for index,row in tqdm(test_id.iterrows()):\n",
    "    user = neighbor_dict[row['id']]['clickHistory'] ##邻居用户\n",
    "    history = behavior_dict[user]\n",
    "    idxs = list(range(len(history)))\n",
    "    np.random.shuffle(idxs)\n",
    "    his_len = len(history)\n",
    "    count = 0\n",
    "    text = []\n",
    "    for x in idxs:\n",
    "        if(count == maxCount):break\n",
    "        tit = title[title['id']==history[x]]['title'].values[0]\n",
    "        if type(tit) == float:continue\n",
    "        text.extend(tit)\n",
    "        count += 1\n",
    "    test_his.append(text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.生成最终的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: UTF-8 -*-\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "train = np.load('./data/bert/15_10_con/train_order.npy',allow_pickle=True)\n",
    "dev = np.load('./data/bert/15_10_con/dev_order.npy',allow_pickle=True)\n",
    "test = np.load('./data/bert/15_10_con/test_order.npy',allow_pickle=True)\n",
    "   \n",
    "his_len = 150\n",
    "curr_len = 10\n",
    "def pad(text,his_len):\n",
    "    arr = text.split(' ')\n",
    "    if(len(arr) < his_len):\n",
    "        arr.extend(['[PAD]'] * (his_len - len(arr)))\n",
    "    else:\n",
    "        arr = arr[:his_len]\n",
    "    return ' '.join(arr)\n",
    "train_file =[]\n",
    "for row in tqdm(train):\n",
    "    row[1] = pad(row[1],his_len)\n",
    "    row[2] = pad(row[2],curr_len)\n",
    "#     row[4] =  pad(row[4],neigh_len)\n",
    "#     train_file.append(['[CLS] '+ row[1]+ ' ' + row[4] +  ' [SEP] ' + row[2] + ' [SEP]',row[3]])\n",
    "    train_file.append(['[CLS] '+ row[1] +   ' [SEP] ' + row[2] + ' [SEP]',row[4]])\n",
    "    \n",
    "pd.DataFrame(train_file).to_csv('./data/bert/15_10_con/train_pair_order.csv',index = False)\n",
    "dev_file = []\n",
    "for row in tqdm(dev):\n",
    "    row[1] = pad(row[1],his_len)\n",
    "    row[2] = pad(row[2],curr_len)\n",
    "# #     row[4] =  pad(row[4],neigh_len)\n",
    "#     dev_file.append(['[CLS] '+ row[1]+ ' ' + row[4] +' [SEP] ' + row[2] + ' [SEP]',row[3]])\n",
    "    dev_file.append(['[CLS] '+ row[1] +' [SEP] ' + row[2] + ' [SEP]',row[4]])\n",
    "    \n",
    "pd.DataFrame(dev_file).to_csv('./data/bert/15_10_con/dev_pair_order.csv',index = False)\n",
    "test_file = []\n",
    "for row in tqdm(test):\n",
    "    row[1] = pad(row[1],his_len)\n",
    "    row[2] = pad(row[2],curr_len)\n",
    "#     row[4] =  pad(row[4],neigh_len)\n",
    "#     test_file.append(['[CLS] '+ row[1]+ ' ' + row[4] +' [SEP] ' + row[2] + ' [SEP]',row[3]])\n",
    "    test_file.append(['[CLS] '+ row[1] + ' [SEP] ' + row[2] + ' [SEP]',row[4]])\n",
    "    \n",
    "pd.DataFrame(test_file).to_csv('./data/bert/15_10_con/test_pair_order.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.load('./data/bert/15_10_con/test_order.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test[1][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_bert import extract_embeddings\n",
    "\n",
    "train = np.load('./data/bert/15_10_con/train.npy')\n",
    "dev = np.load('./data/bert/15_10_con/dev.npy')\n",
    "test = np.load('./data/bert/15_10_con/test.npy')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "model_path = './data/outputs/bert_15_10_con'\n",
    "\n",
    "from keras_bert import extract_embeddings, POOL_NSP, POOL_MAX\n",
    "train_pair = pd.read_csv('./data/bert/15_10_con/train_pair.csv')\n",
    "train_pair = train_pair['0'].apply(lambda x: eval(x)).values.tolist()\n",
    "# dev_pair = pd.read_csv('./data/bert/15_10_con/dev_pair.csv')\n",
    "# dev_pair = dev_pair['0'].apply(lambda x: eval(x)).values.tolist()\n",
    "# test_pair = pd.read_csv('./data/bert/15_10_con/test_pair.csv')\n",
    "# test_pair = test_pair['0'].apply(lambda x: eval(x)).values.tolist()\n",
    "train_embed = []\n",
    "for index,row in enumerate(train_pair):\n",
    "    embed = extract_embeddings(model_path, row)[0][0]\n",
    "    train_embed.append(embed)\n",
    "    print(index)\n",
    "    \n",
    "# dev_embed = extract_embeddings(model_path, dev_pair)\n",
    "# test_embed = extract_embeddings(model_path, test_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maxlen_history = 120\n",
    "maxlen_curr = 30\n",
    "import numpy as np\n",
    "examples = []\n",
    "step = 0\n",
    "for index,row in all_train.iterrows():\n",
    "    temp = []\n",
    "    text = ' '.join(eval(row['history']))\n",
    "    temp.append(text)\n",
    "    text = ' '.join(eval(row['current']))\n",
    "    temp.append(text)\n",
    "    temp.append(row['label'])\n",
    "    examples.append(temp)\n",
    "    step += 1\n",
    "    if(step % 10000 == 0):print(step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print( maxlen_history)\n",
    "print(maxlen_curr)\n",
    "### 训练数据裁剪\n",
    "k = 1\n",
    "train_1 = []\n",
    "index = 0\n",
    "lens = len(examples)\n",
    "while index <(lens):\n",
    "    flag = True\n",
    "    for his in range(k):\n",
    "        if examples[index+his][2] != 0:\n",
    "            flag = False\n",
    "            break\n",
    "    if(flag):\n",
    "        for pos in range(k):\n",
    "            history = examples[pos + index]\n",
    "            history[0] = history[0]\n",
    "            train_1.append(history)\n",
    "        index += k\n",
    "        if(index + k >= lens):break\n",
    "        while(examples[index][2] != 1):\n",
    "            index += 1\n",
    "            if(index + k >= lens):break\n",
    "        if(index + k >= len(examples)):break\n",
    "        history = examples[index]\n",
    "        train_1.append(history)\n",
    "    else:\n",
    "        index += 1\n",
    "    if(len(train_1) % 2000 == 0):print(len(train_1))\n",
    "    if(index + k >= lens):break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "texts = [('all work and no play', 'makes jack a dull boy'),\n",
    "    ('makes jack a dull boy', 'all work and no play')]\n",
    "embeddings = extract_embeddings(model_path, texts)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[1][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "model_name = './data/outputs/bert_15_10_con'  # 指定需下载的预训练模型参数\n",
    "\n",
    "# BERT 在预训练中引入了 [CLS] 和 [SEP] 标记句子的开头和结尾\n",
    "samples = ['[CLS] are you ok？ 0 [SEP]I amgo fine ! 0 [SEP]']  # 准备输入模型的语句\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenized_text = [tokenizer.tokenize(i) for i in samples]\n",
    "\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(i) for i in tokenized_text]\n",
    "input_ids = torch.LongTensor(input_ids)\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./data/train/seprate_10/all_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
